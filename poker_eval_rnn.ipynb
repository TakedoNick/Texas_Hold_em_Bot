{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25010, 11)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('Data/poker_hand/poker-hand-training-true.data', delimiter = ',')\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 11)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = np.genfromtxt('Data/poker_hand/poker-hand-testing.data', delimiter = ',')\n",
    "np.shape(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025010, 11)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = np.concatenate([data, data2], axis=0)\n",
    "np.shape(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025010, 10)\n",
      "(1025010,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = np.split(total_data, np.array([10]), axis = 1)\n",
    "print(np.shape(X))\n",
    "Y = np.squeeze(Y)\n",
    "print(np.shape(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025005</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025006</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025008</th>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025009</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025010 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1    2     3    4     5    6     7    8     9\n",
       "0        1.0  10.0  1.0  11.0  1.0  13.0  1.0  12.0  1.0   1.0\n",
       "1        2.0  11.0  2.0  13.0  2.0  10.0  2.0  12.0  2.0   1.0\n",
       "2        3.0  12.0  3.0  11.0  3.0  13.0  3.0  10.0  3.0   1.0\n",
       "3        4.0  10.0  4.0  11.0  4.0   1.0  4.0  13.0  4.0  12.0\n",
       "4        4.0   1.0  4.0  13.0  4.0  12.0  4.0  11.0  4.0  10.0\n",
       "...      ...   ...  ...   ...  ...   ...  ...   ...  ...   ...\n",
       "1025005  3.0   1.0  1.0  12.0  2.0   9.0  4.0   9.0  2.0   6.0\n",
       "1025006  3.0   3.0  4.0   5.0  2.0   7.0  1.0   4.0  4.0   3.0\n",
       "1025007  1.0  11.0  4.0   7.0  3.0   9.0  1.0  13.0  2.0   7.0\n",
       "1025008  3.0  11.0  1.0   8.0  1.0   1.0  3.0  13.0  2.0   8.0\n",
       "1025009  2.0   5.0  2.0   9.0  4.0   9.0  2.0   3.0  3.0   3.0\n",
       "\n",
       "[1025010 rows x 10 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(X)\n",
    "Y_df = pd.DataFrame(Y)\n",
    "Y_df.hist(bins=range(0,10))\n",
    "plt.xticks(range(0,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class miniRnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(miniRnn, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 10)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "base_model = miniRnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIT = nn.CrossEntropyLoss()\n",
    "# OPT = optim.Adam(base_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "val_data = TensorDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        true_pred = 0\n",
    "        total_pred = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad() # Zeroing the gradients\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the loss and accuracy\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            true_pred += (predicted == labels).sum().item()\n",
    "            total_pred += labels.size(0)\n",
    "        \n",
    "        train_acc = true_pred / total_pred\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {running_loss/len(train_loader)}, Train Acc: {train_acc * 100:.2f}%\")\n",
    "\n",
    "        validate_model(model, val_loader, criterion)\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    true_pred = 0\n",
    "    total_pred = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            true_pred += (predicted == labels).sum().item()\n",
    "            total_pred += labels.size(0)\n",
    "    \n",
    "    val_acc = true_pred / total_pred\n",
    "    print(f\"validation Loss: {val_loss/len(val_loader)}, Validation Acc: {val_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 0.9239132476431661, Train Acc: 56.54%\n",
      "validation Loss: 0.8809878840279788, Validation Acc: 59.90%\n",
      "Epoch [2/30], Train Loss: 0.8980765678671775, Train Acc: 58.38%\n",
      "validation Loss: 0.8385666909252064, Validation Acc: 62.89%\n",
      "Epoch [3/30], Train Loss: 0.8886584201480934, Train Acc: 59.02%\n",
      "validation Loss: 0.8253336007824253, Validation Acc: 64.20%\n",
      "Epoch [4/30], Train Loss: 0.8843196633827265, Train Acc: 59.26%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(model\u001b[38;5;241m=\u001b[39mbase_model, train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, val_loader\u001b[38;5;241m=\u001b[39mval_loader, criterion\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(), optimizer\u001b[38;5;241m=\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(base_model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m), epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m)\n",
      "Cell \u001b[0;32mIn[44], line 28\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m true_pred \u001b[38;5;241m/\u001b[39m total_pred\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m validate_model(model, val_loader, criterion)\n",
      "Cell \u001b[0;32mIn[44], line 38\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, val_loader, criterion)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m---> 38\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     39\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     41\u001b[0m         val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[42], line 20\u001b[0m, in \u001b[0;36mminiRnn.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)))\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m---> 20\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)))\n\u001b[1;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc4(x)\n",
      "File \u001b[0;32m~/Documents/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    202\u001b[0m     bn_training,\n\u001b[1;32m    203\u001b[0m     exponential_average_factor,\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    205\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/functional.py:2822\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2820\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2823\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2824\u001b[0m     weight,\n\u001b[1;32m   2825\u001b[0m     bias,\n\u001b[1;32m   2826\u001b[0m     running_mean,\n\u001b[1;32m   2827\u001b[0m     running_var,\n\u001b[1;32m   2828\u001b[0m     training,\n\u001b[1;32m   2829\u001b[0m     momentum,\n\u001b[1;32m   2830\u001b[0m     eps,\n\u001b[1;32m   2831\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled,\n\u001b[1;32m   2832\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model=base_model, train_loader=train_loader, val_loader=val_loader, criterion=nn.CrossEntropyLoss(), optimizer=optim.Adam(base_model.parameters(), lr = 0.01), epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define mapping for card values and suits\n",
    "card_value_map = {'A': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, \n",
    "                  'T': 10, 'J': 11, 'Q': 12, 'K': 13}\n",
    "suit_map = {'h': 1, 's': 2, 'd': 3, 'c': 4}\n",
    "\n",
    "class_map = {'Pair': 1, 'Two Pair': 2, 'Three of a Kind': 3, 'Straight': 4, \n",
    "             'Straight (Wheel)': 4, 'Flush': 5, 'Full House': 6,\n",
    "             'Four of a Kind': 7, 'Straight Flush': 8, 'Straight Flush (Wheel)': 8,\n",
    "             'Royal Flush': 9, 'High Card': 0}\n",
    "\n",
    "# Define the number of entries needed per class\n",
    "entries_per_class = 10000  # Example: Adjust this to your need (1 million per class)\n",
    "classes = ['Pair', 'High Card', 'Two Pair', 'Straight']  # Extend this with other classes\n",
    "class_count = defaultdict(int)\n",
    "\n",
    "# Initialize an empty list to hold data\n",
    "data = []\n",
    "\n",
    "def process_line(line):\n",
    "    # Split the line by '->' to separate cards and class\n",
    "    _, hand_info = line.strip().split('->')\n",
    "    \n",
    "    # Get the cards and the class (trim spaces)\n",
    "    cards = hand_info.split(',')[0].strip()\n",
    "    hand_class = hand_info.split(',')[1].strip()\n",
    "    hand_class = class_map[hand_class]\n",
    "    # If the class count is already full, skip\n",
    "    if class_count[hand_class] >= entries_per_class:\n",
    "        return None\n",
    "    \n",
    "    # Process the cards into numerical form\n",
    "    card_array = []\n",
    "    for card in cards.split():\n",
    "        value = card_value_map[card[0]]\n",
    "        suit = suit_map[card[1]]\n",
    "        card_array.append([suit, value])\n",
    "    \n",
    "    # Flatten the card_array and append the class to it\n",
    "    card_array_flat = [item for sublist in card_array for item in sublist]\n",
    "    \n",
    "    # Add the class string at the end\n",
    "    card_array_flat.append(hand_class)\n",
    "    \n",
    "    # Increment the class count\n",
    "    class_count[hand_class] += 1\n",
    "    \n",
    "    return card_array_flat\n",
    "\n",
    "def process_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            processed = process_line(line)\n",
    "            if processed:\n",
    "                data.append(processed)\n",
    "            # Stop if we've collected enough entries for each class\n",
    "            if all(count >= entries_per_class for count in class_count.values()):\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83146, 11)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filepath for your text file\n",
    "filename = 'Data/poker_hand/poker_hands_10m.txt'\n",
    "\n",
    "# Process the file\n",
    "process_file(filename)\n",
    "\n",
    "# Convert to numpy array (ignoring the class labels for now)\n",
    "data_array = np.array(data)\n",
    "np.shape(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83146, 10)\n",
      "(83146,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = np.split(data_array, np.array([10]), axis = 1)\n",
    "print(np.shape(X))\n",
    "y = np.squeeze(y)\n",
    "print(np.shape(y))\n",
    "y_df = pd.DataFrame(y)\n",
    "y_df.hist(bins = range(0, 10))\n",
    "plt.xticks(range(0, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xt = torch.tensor(X, dtype=torch.float32)\n",
    "yt = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(Xt, yt, test_size=0.2, random_state=42)\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "val_data = TensorDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 0.8655828668807561, Train Acc: 71.20%\n",
      "validation Loss: 0.3738898421709354, Validation Acc: 85.57%\n",
      "Epoch [2/30], Train Loss: 0.5213040132791951, Train Acc: 80.03%\n",
      "validation Loss: 0.33007439678678147, Validation Acc: 87.91%\n",
      "Epoch [3/30], Train Loss: 0.4647174374272044, Train Acc: 81.98%\n",
      "validation Loss: 0.2839106183212537, Validation Acc: 88.72%\n",
      "Epoch [4/30], Train Loss: 0.4359712728800682, Train Acc: 83.00%\n",
      "validation Loss: 0.3230514363600658, Validation Acc: 87.23%\n",
      "Epoch [5/30], Train Loss: 0.41179428278253627, Train Acc: 83.83%\n",
      "validation Loss: 0.24667163972671216, Validation Acc: 90.19%\n",
      "Epoch [6/30], Train Loss: 0.38096536534050335, Train Acc: 84.99%\n",
      "validation Loss: 0.24880285414938744, Validation Acc: 90.05%\n",
      "Epoch [7/30], Train Loss: 0.36533324715609733, Train Acc: 85.71%\n",
      "validation Loss: 0.2306813833805231, Validation Acc: 90.91%\n",
      "Epoch [8/30], Train Loss: 0.3468276178106092, Train Acc: 86.40%\n",
      "validation Loss: 0.229484302808459, Validation Acc: 91.37%\n",
      "Epoch [9/30], Train Loss: 0.348776501044631, Train Acc: 86.38%\n",
      "validation Loss: 0.19505478642307794, Validation Acc: 93.29%\n",
      "Epoch [10/30], Train Loss: 0.3294967937569779, Train Acc: 87.20%\n",
      "validation Loss: 0.19962031534658028, Validation Acc: 92.25%\n",
      "Epoch [11/30], Train Loss: 0.32753553808881686, Train Acc: 87.38%\n",
      "validation Loss: 0.217730817428002, Validation Acc: 91.67%\n",
      "Epoch [12/30], Train Loss: 0.3208014836463218, Train Acc: 87.69%\n",
      "validation Loss: 0.21328256078637564, Validation Acc: 92.45%\n",
      "Epoch [13/30], Train Loss: 0.3188016641598481, Train Acc: 87.88%\n",
      "validation Loss: 0.18431535377525365, Validation Acc: 93.37%\n",
      "Epoch [14/30], Train Loss: 0.31066814216856775, Train Acc: 88.27%\n",
      "validation Loss: 0.17987427306003295, Validation Acc: 93.52%\n",
      "Epoch [15/30], Train Loss: 0.3036079730695257, Train Acc: 88.65%\n",
      "validation Loss: 0.1701727237409124, Validation Acc: 94.47%\n",
      "Epoch [16/30], Train Loss: 0.3044209855966843, Train Acc: 88.69%\n",
      "validation Loss: 0.16910682293371512, Validation Acc: 94.28%\n",
      "Epoch [17/30], Train Loss: 0.29125403840667924, Train Acc: 89.06%\n",
      "validation Loss: 0.16439829942985223, Validation Acc: 94.35%\n",
      "Epoch [18/30], Train Loss: 0.29477587529959587, Train Acc: 88.90%\n",
      "validation Loss: 0.14651521507364054, Validation Acc: 95.00%\n",
      "Epoch [19/30], Train Loss: 0.2798248431430413, Train Acc: 89.42%\n",
      "validation Loss: 0.15625071882341918, Validation Acc: 93.97%\n",
      "Epoch [20/30], Train Loss: 0.27745963047043637, Train Acc: 89.55%\n",
      "validation Loss: 0.1339715661481023, Validation Acc: 94.89%\n",
      "Epoch [21/30], Train Loss: 0.26696659326553346, Train Acc: 89.86%\n",
      "validation Loss: 0.12384130192490725, Validation Acc: 95.09%\n",
      "Epoch [22/30], Train Loss: 0.25906454609850277, Train Acc: 89.96%\n",
      "validation Loss: 0.10459217849689034, Validation Acc: 95.65%\n",
      "Epoch [23/30], Train Loss: 0.25495786302221507, Train Acc: 90.03%\n",
      "validation Loss: 0.118908779666974, Validation Acc: 94.72%\n",
      "Epoch [24/30], Train Loss: 0.24208379895068133, Train Acc: 90.64%\n",
      "validation Loss: 0.09165595993041419, Validation Acc: 95.75%\n",
      "Epoch [25/30], Train Loss: 0.23011307738219888, Train Acc: 90.73%\n",
      "validation Loss: 0.08991319245945376, Validation Acc: 95.60%\n",
      "Epoch [26/30], Train Loss: 0.20997500625940468, Train Acc: 91.49%\n",
      "validation Loss: 0.08118921241078239, Validation Acc: 96.57%\n",
      "Epoch [27/30], Train Loss: 0.21090161764922624, Train Acc: 91.68%\n",
      "validation Loss: 0.05136294522179434, Validation Acc: 98.77%\n",
      "Epoch [28/30], Train Loss: 0.20237142431836289, Train Acc: 92.18%\n",
      "validation Loss: 0.049188774458777444, Validation Acc: 99.40%\n",
      "Epoch [29/30], Train Loss: 0.19477368850941554, Train Acc: 92.55%\n",
      "validation Loss: 0.04740133439011585, Validation Acc: 97.88%\n",
      "Epoch [30/30], Train Loss: 0.18774645429892609, Train Acc: 92.90%\n",
      "validation Loss: 0.07259598333531847, Validation Acc: 98.08%\n"
     ]
    }
   ],
   "source": [
    "train_model(model=base_model, train_loader=train_loader, val_loader=val_loader, criterion=nn.CrossEntropyLoss(), optimizer=optim.Adam(base_model.parameters(), lr = 0.01), epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
